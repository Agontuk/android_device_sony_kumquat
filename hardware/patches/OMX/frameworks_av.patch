diff --git a/frameworks/av/camera/CameraParameters.cpp b/frameworks/av/camera/CameraParameters.cpp
index af091f4..a1d3865 100644
--- a/frameworks/av/camera/CameraParameters.cpp
+++ b/frameworks/av/camera/CameraParameters.cpp
@@ -172,6 +172,33 @@ const char CameraParameters::FOCUS_MODE_CONTINUOUS_PICTURE[] = "continuous-pictu
 const char CameraParameters::LIGHTFX_LOWLIGHT[] = "low-light";
 const char CameraParameters::LIGHTFX_HDR[] = "high-dynamic-range";
 
+#ifdef STE_HARDWARE
+const char CameraParameters::SCENE_MODE_BACKLIGHT[] = "backlight";
+const char CameraParameters::SCENE_MODE_DUSKDAWN[] = "duskdawn";
+const char CameraParameters::SCENE_MODE_FALLCOLOR[] = "fallcolor";
+const char CameraParameters::SCENE_MODE_TEXT[] = "text";
+const char CameraParameters::PIXEL_FORMAT_YUV420SPNV12[] = "yuv420spnv12";
+const char CameraParameters::PIXEL_FORMAT_YUV420MB[] = "yuv420mb";
+const char CameraParameters::PIXEL_FORMAT_YVU422SP[] = "yvu422sp";
+const char CameraParameters::PIXEL_FORMAT_YVU422P[] = "yvu422p";
+const char CameraParameters::PIXEL_FORMAT_YVU420SP[] = "yvu420sp";
+const char CameraParameters::PIXEL_FORMAT_YVU420P[]  = "yvu420p";
+const char CameraParameters::FOCUS_MODE_FACEDETECT[] = "facedetect";
+const char CameraParameters::FOCUS_MODE_TOUCHAF[] = "touchaf";
+const char CameraParameters::ISO_50[] = "ISO50";
+const char CameraParameters::KEY_ANTI_SHAKE_MODE[] = "antishake";
+const char CameraParameters::KEY_AUTO_CONTRAST[] = "auto-contrast";
+const char CameraParameters::KEY_BEAUTY_MODE[] = "beauty";
+const char CameraParameters::KEY_BLUR_MODE[] = "blur";
+const char CameraParameters::KEY_VINTAGE_MODE[] = "vintagemode";
+const char CameraParameters::KEY_WDR_MODE[] = "wdr";
+const char CameraParameters::VINTAGE_MODE_BNW[] = "bnw";
+const char CameraParameters::VINTAGE_MODE_COOL[] = "cool";
+const char CameraParameters::VINTAGE_MODE_NORMAL[] = "normal";
+const char CameraParameters::VINTAGE_MODE_OFF[] = "off";
+const char CameraParameters::VINTAGE_MODE_WARM[] = "warm";
+#endif
+
 CameraParameters::CameraParameters()
                 : mMap()
 {
@@ -233,6 +260,11 @@ void CameraParameters::unflatten(const String8 &params)
     }
 }
 
+#ifdef STE_HARDWARE
+// keys for record stride and sliceheight
+const char CameraParameters::KEY_RECORD_STRIDE[] = "record-stride";
+const char CameraParameters::KEY_RECORD_SLICE_HEIGHT[] = "record-slice-height";
+#endif
 
 void CameraParameters::set(const char *key, const char *value)
 {
diff --git a/frameworks/av/include/camera/CameraParameters.h b/frameworks/av/include/camera/CameraParameters.h
index d521543..18cf771 100644
--- a/frameworks/av/include/camera/CameraParameters.h
+++ b/frameworks/av/include/camera/CameraParameters.h
@@ -674,6 +674,38 @@ public:
     // High-dynamic range mode
     static const char LIGHTFX_HDR[];
 
+#ifdef STE_HARDWARE
+    // keys for record stride and slice height
+    static const char KEY_RECORD_STRIDE[];
+    static const char KEY_RECORD_SLICE_HEIGHT[];
+    static const char PIXEL_FORMAT_YUV420SPNV12[]; // NV12
+    static const char PIXEL_FORMAT_YVU422SP[];
+    static const char PIXEL_FORMAT_YVU422P[];
+    static const char PIXEL_FORMAT_YVU420SP[];
+    static const char PIXEL_FORMAT_YVU420P[];
+    static const char PIXEL_FORMAT_YUV420MB[];
+    static const char FOCUS_MODE_FACEDETECT[];
+    static const char FOCUS_MODE_TOUCHAF[];
+    static const char ISO_50[];
+    static const char KEY_ANTI_SHAKE_MODE[];
+    static const char KEY_AUTO_CONTRAST[];
+    static const char KEY_BEAUTY_MODE[];
+    static const char KEY_BLUR_MODE[];
+    static const char KEY_VINTAGE_MODE[];
+    static const char KEY_WDR_MODE[];
+    static const char VINTAGE_MODE_BNW[];
+    static const char VINTAGE_MODE_COOL[];
+    static const char VINTAGE_MODE_NORMAL[];
+    static const char VINTAGE_MODE_OFF[];
+    static const char VINTAGE_MODE_WARM[];
+    static const char SCENE_MODE_DUSKDAWN[];
+    static const char SCENE_MODE_FALL[];
+    static const char SCENE_MODE_FALL_COLOR[];
+    static const char SCENE_MODE_BACKLIGHT[];
+    static const char SCENE_MODE_FALLCOLOR[];
+    static const char SCENE_MODE_TEXT[];
+#endif
+
 private:
     DefaultKeyedVector<String8,String8>    mMap;
 };
diff --git a/frameworks/av/include/media/AudioParameter.h b/frameworks/av/include/media/AudioParameter.h
index 891bc4b..263ace7 100644
--- a/frameworks/av/include/media/AudioParameter.h
+++ b/frameworks/av/include/media/AudioParameter.h
@@ -48,6 +48,9 @@ public:
     static const char * const keyFrameCount;
     static const char * const keyInputSource;
     static const char * const keyScreenState;
+#ifdef STE_AUDIO
+    static const char *keySinkLatency;
+#endif
 
     String8 toString();
 
diff --git a/frameworks/av/include/media/AudioRecord.h b/frameworks/av/include/media/AudioRecord.h
index 052064d..2251fa0 100644
--- a/frameworks/av/include/media/AudioRecord.h
+++ b/frameworks/av/include/media/AudioRecord.h
@@ -493,6 +493,10 @@ private:
 
     bool                    mInOverrun;         // whether recorder is currently in overrun state
 
+#ifdef STE_AUDIO
+    audio_input_clients     *mpInputClientId;
+#endif
+
 private:
     class DeathNotifier : public IBinder::DeathRecipient {
     public:
diff --git a/frameworks/av/include/media/AudioSystem.h b/frameworks/av/include/media/AudioSystem.h
index 4c22412..270a92d 100644
--- a/frameworks/av/include/media/AudioSystem.h
+++ b/frameworks/av/include/media/AudioSystem.h
@@ -27,6 +27,9 @@
 namespace android {
 
 typedef void (*audio_error_callback)(status_t err);
+#ifdef STE_AUDIO
+typedef void (*latency_update_callback)(void *cookie, audio_io_handle_t output, uint32_t sinkLatency);
+#endif
 
 class IAudioFlinger;
 class IAudioPolicyService;
@@ -138,6 +141,11 @@ public:
     static void acquireAudioSessionId(int audioSession);
     static void releaseAudioSessionId(int audioSession);
 
+#ifdef STE_AUDIO
+    static int registerLatencyNotificationClient(latency_update_callback cb, void *cookie, audio_io_handle_t output);
+    static void unregisterLatencyNotificationClient(int clientId);
+#endif
+
     // types of io configuration change events received with ioConfigChanged()
     enum io_config_event {
         OUTPUT_OPENED,
@@ -147,6 +155,9 @@ public:
         INPUT_CLOSED,
         INPUT_CONFIG_CHANGED,
         STREAM_CONFIG_CHANGED,
+#ifdef STE_AUDIO
+        SINK_LATENCY_CHANGED,
+#endif
         NUM_CONFIG_EVENTS
     };
 
@@ -210,7 +221,13 @@ public:
                                     uint32_t samplingRate = 0,
                                     audio_format_t format = AUDIO_FORMAT_DEFAULT,
                                     audio_channel_mask_t channelMask = AUDIO_CHANNEL_IN_MONO,
+#ifdef STE_AUDIO
+                                    audio_in_acoustics_t acoustics = (audio_in_acoustics_t)0,
+                                    int sessionId = 0,
+                                    audio_input_clients *inputClientId = NULL);
+#else
                                     int sessionId = 0);
+#endif
     static status_t startInput(audio_io_handle_t input);
     static status_t stopInput(audio_io_handle_t input);
     static void releaseInput(audio_io_handle_t input);
@@ -285,6 +302,14 @@ private:
         virtual void binderDied(const wp<IBinder>& who);
     };
 
+#ifdef STE_AUDIO
+    struct NotificationClient : public RefBase {
+        latency_update_callback mCb;
+        void *mCookie;
+        audio_io_handle_t mOutput;
+    };
+#endif
+
     static sp<AudioFlingerClient> gAudioFlingerClient;
     static sp<AudioPolicyServiceClient> gAudioPolicyServiceClient;
     friend class AudioFlingerClient;
@@ -307,6 +332,12 @@ private:
     // list of output descriptors containing cached parameters
     // (sampling rate, framecount, channel count...)
     static DefaultKeyedVector<audio_io_handle_t, OutputDescriptor *> gOutputs;
+
+#ifdef STE_AUDIO
+    static Mutex gLatencyLock;
+    static int gNextUniqueLatencyId;
+    static DefaultKeyedVector<int, sp<AudioSystem::NotificationClient> > gLatencyNotificationClients;
+#endif
 };
 
 };  // namespace android
diff --git a/frameworks/av/include/media/AudioTrack.h b/frameworks/av/include/media/AudioTrack.h
index f6646ab..85fd225 100644
--- a/frameworks/av/include/media/AudioTrack.h
+++ b/frameworks/av/include/media/AudioTrack.h
@@ -59,6 +59,9 @@ public:
                                     // (See setPositionUpdatePeriod()).
         EVENT_BUFFER_END = 5,       // Playback head is at the end of the buffer.
                                     // Not currently used by android.media.AudioTrack.
+#ifdef STE_AUDIO
+        EVENT_LATENCY_CHANGED = 6,   // Audio sink latency has changed.
+#endif
         EVENT_NEW_IAUDIOTRACK = 6,  // IAudioTrack was re-created, either due to re-routing and
                                     // voluntary invalidation by mediaserver, or mediaserver crash.
         EVENT_STREAM_END = 7,       // Sent after all the buffers queued in AF and HW are played
@@ -650,6 +653,11 @@ protected:
             // FIXME enum is faster than strcmp() for parameter 'from'
             status_t restoreTrack_l(const char *from);
 
+#ifdef STE_AUDIO
+            static void LatencyCallback(void *cookie, audio_io_handle_t output,
+                                 uint32_t sinkLatency);
+#endif
+
             bool     isOffloaded() const
                 { return (mFlags & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != 0; }
 
@@ -729,6 +737,10 @@ protected:
     int                     mPreviousPriority;          // before start()
     SchedPolicy             mPreviousSchedulingGroup;
     bool                    mAwaitBoost;    // thread should wait for priority boost before running
+#ifdef STE_AUDIO
+    int                     mLatencyClientId;
+#endif
+
 
     // The proxy should only be referenced while a lock is held because the proxy isn't
     // multi-thread safe, especially the SingleStateQueue part of the proxy.
diff --git a/frameworks/av/include/media/IAudioFlinger.h b/frameworks/av/include/media/IAudioFlinger.h
index 282f275..4a36bab 100644
--- a/frameworks/av/include/media/IAudioFlinger.h
+++ b/frameworks/av/include/media/IAudioFlinger.h
@@ -156,12 +156,26 @@ public:
     virtual status_t suspendOutput(audio_io_handle_t output) = 0;
     virtual status_t restoreOutput(audio_io_handle_t output) = 0;
 
+#ifdef STE_AUDIO
+    virtual uint32_t *addInputClient(uint32_t clientId) = 0;
+    virtual status_t removeInputClient(uint32_t *pClientId) = 0;
+
+    virtual audio_io_handle_t openInput(audio_module_handle_t module,
+                                        audio_devices_t *pDevices,
+                                        uint32_t *pSamplingRate,
+                                        audio_format_t *pFormat,
+                                        audio_channel_mask_t *pChannelMask,
+                                        audio_input_clients *inputClientId = NULL) = 0;
+    virtual status_t closeInput(audio_io_handle_t input,
+                                audio_input_clients *inputClientId = NULL) = 0;
+#else
     virtual audio_io_handle_t openInput(audio_module_handle_t module,
                                         audio_devices_t *pDevices,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
                                         audio_channel_mask_t *pChannelMask) = 0;
     virtual status_t closeInput(audio_io_handle_t input) = 0;
+#endif
 
     virtual status_t setStreamOutput(audio_stream_type_t stream, audio_io_handle_t output) = 0;
 
@@ -197,6 +211,14 @@ public:
     virtual status_t moveEffects(int session, audio_io_handle_t srcOutput,
                                     audio_io_handle_t dstOutput) = 0;
 
+#ifdef STE_AUDIO
+    virtual size_t readInput(audio_io_handle_t input,
+                            audio_input_clients inputClientId,
+                            void *buffer,
+                            uint32_t bytes,
+                            uint32_t *pOverwrittenBytes) = 0;
+#endif
+
     virtual audio_module_handle_t loadHwModule(const char *name) = 0;
 
     // helpers for android.media.AudioManager.getProperty(), see description there for meaning
diff --git a/frameworks/av/include/media/IAudioPolicyService.h b/frameworks/av/include/media/IAudioPolicyService.h
index 09b9ea6..460efb4 100644
--- a/frameworks/av/include/media/IAudioPolicyService.h
+++ b/frameworks/av/include/media/IAudioPolicyService.h
@@ -66,7 +66,12 @@ public:
                                     uint32_t samplingRate = 0,
                                     audio_format_t format = AUDIO_FORMAT_DEFAULT,
                                     audio_channel_mask_t channelMask = 0,
+#ifdef STE_AUDIO
+                                    int audioSession = 0,
+                                    audio_input_clients *inputClientId = NULL) = 0;
+#else
                                     int audioSession = 0) = 0;
+#endif
     virtual status_t startInput(audio_io_handle_t input) = 0;
     virtual status_t stopInput(audio_io_handle_t input) = 0;
     virtual void releaseInput(audio_io_handle_t input) = 0;
diff --git a/frameworks/av/include/media/stagefright/ColorConverter.h b/frameworks/av/include/media/stagefright/ColorConverter.h
index 85ba920..014fc7a 100644
--- a/frameworks/av/include/media/stagefright/ColorConverter.h
+++ b/frameworks/av/include/media/stagefright/ColorConverter.h
@@ -73,6 +73,11 @@ private:
     status_t convertQCOMYUV420SemiPlanar(
             const BitmapParams &src, const BitmapParams &dst);
 
+#ifdef STE_HARDWARE
+    status_t convertSTEYUV420PackedSemiPlanarMB(
+            const BitmapParams &src, const BitmapParams &dst);
+#endif
+
     status_t convertYUV420SemiPlanar(
             const BitmapParams &src, const BitmapParams &dst);
 
diff --git a/frameworks/av/include/media/stagefright/MediaDefs.h b/frameworks/av/include/media/stagefright/MediaDefs.h
index 85693d4..df3846e 100644
--- a/frameworks/av/include/media/stagefright/MediaDefs.h
+++ b/frameworks/av/include/media/stagefright/MediaDefs.h
@@ -27,8 +27,14 @@ extern const char *MEDIA_MIMETYPE_VIDEO_VP9;
 extern const char *MEDIA_MIMETYPE_VIDEO_AVC;
 extern const char *MEDIA_MIMETYPE_VIDEO_MPEG4;
 extern const char *MEDIA_MIMETYPE_VIDEO_H263;
+#ifdef STE_HARDWARE
+extern const char *MEDIA_MIMETYPE_VIDEO_H263_SW;
+#endif
 extern const char *MEDIA_MIMETYPE_VIDEO_MPEG2;
 extern const char *MEDIA_MIMETYPE_VIDEO_RAW;
+#ifdef STE_HARDWARE
+extern const char *MEDIA_MIMETYPE_VIDEO_VC1;
+#endif
 
 extern const char *MEDIA_MIMETYPE_AUDIO_AMR_NB;
 extern const char *MEDIA_MIMETYPE_AUDIO_AMR_WB;
diff --git a/frameworks/av/include/media/stagefright/OMXCodec.h b/frameworks/av/include/media/stagefright/OMXCodec.h
index daaf20f..0a8fa52 100644
--- a/frameworks/av/include/media/stagefright/OMXCodec.h
+++ b/frameworks/av/include/media/stagefright/OMXCodec.h
@@ -86,6 +86,10 @@ struct OMXCodec : public MediaSource,
     // from MediaBufferObserver
     virtual void signalBufferReturned(MediaBuffer *buffer);
 
+#ifdef STE_HARDWARE
+    static uint32_t OmxToHALFormat(OMX_COLOR_FORMATTYPE omxValue);
+#endif
+
     enum Quirks {
         kNeedsFlushBeforeDisable              = 1,
         kWantsNALFragments                    = 2,
@@ -100,6 +104,9 @@ struct OMXCodec : public MediaSource,
         kSupportsMultipleFramesPerInputBuffer = 1024,
         kRequiresLargerEncoderOutputBuffer    = 2048,
         kOutputBuffersAreUnreadable           = 4096,
+#ifdef STE_HARDWARE
+        kRequiresStoreMetaDataBeforeIdle      = 16384,
+#endif
     };
 
     struct CodecNameAndQuirks {
diff --git a/frameworks/av/include/private/media/AudioTrackShared.h b/frameworks/av/include/private/media/AudioTrackShared.h
index 2d033e6..ac970e7 100644
--- a/frameworks/av/include/private/media/AudioTrackShared.h
+++ b/frameworks/av/include/private/media/AudioTrackShared.h
@@ -106,6 +106,11 @@ struct audio_track_cblk_t
                                         // up (V) by server or binderDied() or interrupt()
 #define CBLK_FUTEX_WAKE 1               // if event flag bit is set, then a deferred wake is pending
 
+                // if there is a shared buffer, "buffers" is the value of pointer() for the shared
+                // buffer, otherwise "buffers" points immediately after the control block
+                void*       buffers;
+                uint32_t    frameCount;
+
 private:
 
                 size_t      mMinimum;       // server wakes up client if available >= mMinimum
@@ -130,6 +135,8 @@ private:
 
 public:
 
+                uint32_t    sampleRate;
+
     volatile    int32_t     mFlags;         // combinations of CBLK_*
 
                 // Cache line boundary (32 bytes)
diff --git a/frameworks/av/media/libmedia/AudioParameter.cpp b/frameworks/av/media/libmedia/AudioParameter.cpp
index 33dbf0b..3f197a1 100644
--- a/frameworks/av/media/libmedia/AudioParameter.cpp
+++ b/frameworks/av/media/libmedia/AudioParameter.cpp
@@ -32,6 +32,9 @@ const char * const AudioParameter::keyChannels = AUDIO_PARAMETER_STREAM_CHANNELS
 const char * const AudioParameter::keyFrameCount = AUDIO_PARAMETER_STREAM_FRAME_COUNT;
 const char * const AudioParameter::keyInputSource = AUDIO_PARAMETER_STREAM_INPUT_SOURCE;
 const char * const AudioParameter::keyScreenState = AUDIO_PARAMETER_KEY_SCREEN_STATE;
+#ifdef STE_AUDIO
+const char *AudioParameter::keySinkLatency = "sink_latency";
+#endif
 
 AudioParameter::AudioParameter(const String8& keyValuePairs)
 {
diff --git a/frameworks/av/media/libmedia/AudioRecord.cpp b/frameworks/av/media/libmedia/AudioRecord.cpp
index 666fafa..0a15c5b 100644
--- a/frameworks/av/media/libmedia/AudioRecord.cpp
+++ b/frameworks/av/media/libmedia/AudioRecord.cpp
@@ -72,8 +72,18 @@ status_t AudioRecord::getMinFrameCount(
 
 AudioRecord::AudioRecord()
     : mStatus(NO_INIT), mSessionId(0),
+#ifdef STE_AUDIO
+      mpInputClientId(NULL),
+#endif
       mPreviousPriority(ANDROID_PRIORITY_NORMAL), mPreviousSchedulingGroup(SP_DEFAULT)
 {
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        mpInputClientId = (audio_input_clients*)audioFlinger->addInputClient(
+                                                 (uint32_t)AUDIO_INPUT_CLIENT_RECORD);
+    }
+#endif
 }
 
 AudioRecord::AudioRecord(
@@ -89,10 +99,21 @@ AudioRecord::AudioRecord(
         transfer_type transferType,
         audio_input_flags_t flags)
     : mStatus(NO_INIT), mSessionId(0),
+#ifdef STE_AUDIO
+      mpInputClientId(NULL),
+#endif
       mPreviousPriority(ANDROID_PRIORITY_NORMAL),
       mPreviousSchedulingGroup(SP_DEFAULT),
       mProxy(NULL)
 {
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        mpInputClientId = (audio_input_clients*)audioFlinger->addInputClient(
+                                                 (uint32_t)AUDIO_INPUT_CLIENT_RECORD);
+    }
+#endif
+
     mStatus = set(inputSource, sampleRate, format, channelMask, frameCount, cbf, user,
             notificationFrames, false /*threadCanCallJava*/, sessionId, transferType);
 }
@@ -117,6 +138,12 @@ AudioRecord::~AudioRecord()
         IPCThreadState::self()->flushCommands();
         AudioSystem::releaseAudioSessionId(mSessionId);
     }
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        audioFlinger->removeInputClient((uint32_t*)mpInputClientId);
+    }
+#endif
 }
 
 status_t AudioRecord::set(
@@ -342,6 +369,12 @@ void AudioRecord::stop()
         setpriority(PRIO_PROCESS, 0, mPreviousPriority);
         set_sched_policy(0, mPreviousSchedulingGroup);
     }
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        audioFlinger->removeInputClient((uint32_t*)mpInputClientId);
+    }
+#endif
 }
 
 bool AudioRecord::stopped() const
@@ -456,7 +489,14 @@ status_t AudioRecord::openRecord_l(size_t epoch)
     }
 
     audio_io_handle_t input = AudioSystem::getInput(mInputSource, mSampleRate, mFormat,
-            mChannelMask, mSessionId);
+            mChannelMask,
+#ifdef STE_AUDIO
+            (audio_in_acoustics_t)0,
+            mSessionId,
+            mpInputClientId);
+#else
+            mSessionId);
+#endif
     if (input == 0) {
         ALOGE("Could not get audio input for record source %d", mInputSource);
         return BAD_VALUE;
diff --git a/frameworks/av/media/libmedia/AudioSystem.cpp b/frameworks/av/media/libmedia/AudioSystem.cpp
index cc5b810..edc7f99 100644
--- a/frameworks/av/media/libmedia/AudioSystem.cpp
+++ b/frameworks/av/media/libmedia/AudioSystem.cpp
@@ -45,6 +45,12 @@ audio_format_t AudioSystem::gPrevInFormat = AUDIO_FORMAT_PCM_16_BIT;
 audio_channel_mask_t AudioSystem::gPrevInChannelMask = AUDIO_CHANNEL_IN_MONO;
 size_t AudioSystem::gInBuffSize = 0;
 
+#ifdef STE_AUDIO
+// Clients for receiving latency update notifications
+Mutex AudioSystem::gLatencyLock;
+int AudioSystem::gNextUniqueLatencyId = 0;
+DefaultKeyedVector<int, sp<AudioSystem::NotificationClient> > AudioSystem::gLatencyNotificationClients(0);
+#endif
 
 // establish binder interface to AudioFlinger service
 const sp<IAudioFlinger>& AudioSystem::get_audio_flinger()
@@ -417,9 +423,36 @@ void AudioSystem::releaseAudioSessionId(int audioSession) {
     }
 }
 
+#ifdef STE_AUDIO
+int AudioSystem::registerLatencyNotificationClient(latency_update_callback cb,
+        void *cookie, audio_io_handle_t output) {
+    Mutex::Autolock _l(gLatencyLock);
+
+    sp<NotificationClient> notificationClient = new NotificationClient();
+    notificationClient->mCb = cb;
+    notificationClient->mCookie = cookie;
+    notificationClient->mOutput = output;
+
+    gNextUniqueLatencyId++;
+    gLatencyNotificationClients.add(gNextUniqueLatencyId, notificationClient);
+    return gNextUniqueLatencyId;
+}
+
+void AudioSystem::unregisterLatencyNotificationClient(int clientId) {
+    Mutex::Autolock _l(gLatencyLock);
+    gLatencyNotificationClients.removeItem(clientId);
+}
+#endif
+
 // ---------------------------------------------------------------------------
 
 void AudioSystem::AudioFlingerClient::binderDied(const wp<IBinder>& who) {
+#ifdef STE_AUDIO
+    gLatencyLock.lock();
+    AudioSystem::gLatencyNotificationClients.clear();
+    gLatencyLock.unlock();
+#endif
+
     Mutex::Autolock _l(AudioSystem::gLock);
 
     AudioSystem::gAudioFlinger.clear();
@@ -488,6 +521,22 @@ void AudioSystem::AudioFlingerClient::ioConfigChanged(int event, audio_io_handle
         outputDesc =  new OutputDescriptor(*desc);
         gOutputs.replaceValueFor(ioHandle, outputDesc);
     } break;
+#ifdef STE_AUDIO
+    case SINK_LATENCY_CHANGED: {
+        int sinkLatency = *((int*)param2);
+        gLock.unlock();
+        gLatencyLock.lock();
+        size_t size = gLatencyNotificationClients.size();
+        for (size_t i = 0; i < size; i++) {
+            sp<NotificationClient> client = gLatencyNotificationClients.valueAt(i);
+            if (client->mOutput == ioHandle) {
+                (*client->mCb)(client->mCookie, ioHandle, sinkLatency);
+            }
+        }
+        gLatencyLock.unlock();
+        gLock.lock();
+    } break;
+#endif
     case INPUT_OPENED:
     case INPUT_CLOSED:
     case INPUT_CONFIG_CHANGED:
@@ -605,7 +654,11 @@ audio_io_handle_t AudioSystem::getOutput(audio_stream_type_t stream,
 {
     const sp<IAudioPolicyService>& aps = AudioSystem::get_audio_policy_service();
     if (aps == 0) return 0;
+#ifdef STE_AUDIO
+    return aps->getOutput(stream, samplingRate, format, channelMask, flags, NULL);
+#else
     return aps->getOutput(stream, samplingRate, format, channelMask, flags, offloadInfo);
+#endif
 }
 
 status_t AudioSystem::startOutput(audio_io_handle_t output,
@@ -637,11 +690,21 @@ audio_io_handle_t AudioSystem::getInput(audio_source_t inputSource,
                                     uint32_t samplingRate,
                                     audio_format_t format,
                                     audio_channel_mask_t channelMask,
+#ifdef STE_AUDIO
+                                    audio_in_acoustics_t acoustics,
+                                    int sessionId,
+                                    audio_input_clients *inputClientId)
+#else
                                     int sessionId)
+#endif
 {
     const sp<IAudioPolicyService>& aps = AudioSystem::get_audio_policy_service();
     if (aps == 0) return 0;
+#ifdef STE_AUDIO
+    return aps->getInput(inputSource, samplingRate, format, channelMask, sessionId, inputClientId);
+#else
     return aps->getInput(inputSource, samplingRate, format, channelMask, sessionId);
+#endif
 }
 
 status_t AudioSystem::startInput(audio_io_handle_t input)
diff --git a/frameworks/av/media/libmedia/AudioTrack.cpp b/frameworks/av/media/libmedia/AudioTrack.cpp
index a9d6993..24a7eed 100644
--- a/frameworks/av/media/libmedia/AudioTrack.cpp
+++ b/frameworks/av/media/libmedia/AudioTrack.cpp
@@ -156,6 +156,9 @@ AudioTrack::~AudioTrack()
         IPCThreadState::self()->flushCommands();
         AudioSystem::releaseAudioSessionId(mSessionId);
     }
+#ifdef STE_AUDIO
+        AudioSystem::unregisterLatencyNotificationClient(mLatencyClientId);
+#endif
 }
 
 status_t AudioTrack::set(
@@ -1111,6 +1114,11 @@ status_t AudioTrack::obtainBuffer(Buffer* audioBuffer, int32_t waitCount)
         audioBuffer->raw = NULL;
         return INVALID_OPERATION;
     }
+#ifdef STE_AUDIO
+    if (mLatencyClientId != -1) {
+        AudioSystem::unregisterLatencyNotificationClient(mLatencyClientId);
+    }
+#endif
 
     const struct timespec *requested;
     if (waitCount == -1) {
@@ -1804,6 +1812,15 @@ uint32_t AudioTrack::getUnderrunFrames() const
     return mProxy->getUnderrunFrames();
 }
 
+#ifdef STE_AUDIO
+// static
+void AudioTrack::LatencyCallback(void *cookie, audio_io_handle_t output, uint32_t sinkLatency)
+{
+    AudioTrack *me = static_cast<AudioTrack *>(cookie);
+    me->mLatency = sinkLatency + (1000*me->mCblk->frameCount) / me->mCblk->sampleRate;
+}
+#endif
+
 // =========================================================================
 
 void AudioTrack::DeathNotifier::binderDied(const wp<IBinder>& who)
diff --git a/frameworks/av/media/libmedia/IAudioFlinger.cpp b/frameworks/av/media/libmedia/IAudioFlinger.cpp
index 86ff8bd..53de475 100644
--- a/frameworks/av/media/libmedia/IAudioFlinger.cpp
+++ b/frameworks/av/media/libmedia/IAudioFlinger.cpp
@@ -56,6 +56,10 @@ enum {
     CLOSE_OUTPUT,
     SUSPEND_OUTPUT,
     RESTORE_OUTPUT,
+#ifdef STE_AUDIO
+    ADD_INPUT_CLIENT,
+    REMOVE_INPUT_CLIENT,
+#endif
     OPEN_INPUT,
     CLOSE_INPUT,
     SET_STREAM_OUTPUT,
@@ -74,6 +78,9 @@ enum {
     GET_PRIMARY_OUTPUT_SAMPLING_RATE,
     GET_PRIMARY_OUTPUT_FRAME_COUNT,
     SET_LOW_RAM_DEVICE,
+#ifdef STE_AUDIO
+    READ_INPUT,
+#endif
 };
 
 class BpAudioFlinger : public BpInterface<IAudioFlinger>
@@ -465,11 +472,36 @@ public:
         return reply.readInt32();
     }
 
+#ifdef STE_AUDIO
+    virtual uint32_t *addInputClient(uint32_t clientId)
+    {
+        Parcel data, reply;
+        data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
+        data.writeInt32(clientId);
+        remote()->transact(ADD_INPUT_CLIENT, data, &reply);
+        return (uint32_t*) reply.readIntPtr();
+    }
+
+    virtual status_t removeInputClient(uint32_t *pClientId)
+    {
+        Parcel data, reply;
+        data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
+        data.writeIntPtr((intptr_t)pClientId);
+        remote()->transact(REMOVE_INPUT_CLIENT, data, &reply);
+        return reply.readInt32();
+    }
+#endif
+
     virtual audio_io_handle_t openInput(audio_module_handle_t module,
                                         audio_devices_t *pDevices,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                        audio_channel_mask_t *pChannelMask,
+                                        audio_input_clients *pInputClientId)
+#else
                                         audio_channel_mask_t *pChannelMask)
+#endif
     {
         Parcel data, reply;
         audio_devices_t devices = pDevices != NULL ? *pDevices : (audio_devices_t)0;
@@ -484,6 +516,9 @@ public:
         data.writeInt32(samplingRate);
         data.writeInt32(format);
         data.writeInt32(channelMask);
+#ifdef STE_AUDIO
+        data.writeIntPtr((intptr_t)pInputClientId);
+#endif
         remote()->transact(OPEN_INPUT, data, &reply);
         audio_io_handle_t input = (audio_io_handle_t) reply.readInt32();
         devices = (audio_devices_t)reply.readInt32();
@@ -497,7 +532,11 @@ public:
         return input;
     }
 
+#ifdef STE_AUDIO
+    virtual status_t closeInput(int input, audio_input_clients *inputClientId)
+#else
     virtual status_t closeInput(int input)
+#endif
     {
         Parcel data, reply;
         data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
@@ -555,6 +594,22 @@ public:
         return reply.readInt32();
     }
 
+#ifdef STE_AUDIO
+    virtual size_t readInput(audio_io_handle_t input, audio_input_clients inputClientId,
+            void *buffer, uint32_t bytes, uint32_t *pOverwrittenBytes)
+    {
+        Parcel data, reply;
+        data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
+        data.writeInt32(input);
+        data.writeInt32((uint32_t) inputClientId);
+        data.writeIntPtr((intptr_t) buffer);
+        data.writeInt32(bytes);
+        data.writeIntPtr((intptr_t) pOverwrittenBytes);
+        remote()->transact(READ_INPUT, data, &reply);
+        return reply.readInt32();
+    }
+#endif
+
     virtual int newAudioSessionId()
     {
         Parcel data, reply;
@@ -972,6 +1027,20 @@ status_t BnAudioFlinger::onTransact(
             reply->writeInt32(restoreOutput((audio_io_handle_t) data.readInt32()));
             return NO_ERROR;
         } break;
+#ifdef STE_AUDIO
+        case ADD_INPUT_CLIENT: {
+            CHECK_INTERFACE(IAudioFlinger, data, reply);
+            uint32_t clientId = data.readInt32();
+            reply->writeIntPtr((intptr_t)addInputClient(clientId));
+            return NO_ERROR;
+        } break;
+        case REMOVE_INPUT_CLIENT: {
+            CHECK_INTERFACE(IAudioFlinger, data, reply);
+            uint32_t *pClientId = (uint32_t*) data.readIntPtr();
+            reply->writeInt32(removeInputClient(pClientId));
+            return NO_ERROR;
+        } break;
+#endif
         case OPEN_INPUT: {
             CHECK_INTERFACE(IAudioFlinger, data, reply);
             audio_module_handle_t module = (audio_module_handle_t)data.readInt32();
@@ -979,12 +1048,20 @@ status_t BnAudioFlinger::onTransact(
             uint32_t samplingRate = data.readInt32();
             audio_format_t format = (audio_format_t) data.readInt32();
             audio_channel_mask_t channelMask = (audio_channel_mask_t)data.readInt32();
+#ifdef STE_AUDIO
+            audio_input_clients *inputClientId = (audio_input_clients*) data.readIntPtr();
+#endif
 
             audio_io_handle_t input = openInput(module,
                                              &devices,
                                              &samplingRate,
                                              &format,
+#ifdef STE_AUDIO
+                                             &channelMask,
+                                             inputClientId);
+#else
                                              &channelMask);
+#endif
             reply->writeInt32((int32_t) input);
             reply->writeInt32(devices);
             reply->writeInt32(samplingRate);
@@ -994,7 +1071,13 @@ status_t BnAudioFlinger::onTransact(
         } break;
         case CLOSE_INPUT: {
             CHECK_INTERFACE(IAudioFlinger, data, reply);
+#ifdef STE_AUDIO
+            uint32_t input = data.readInt32();
+            audio_input_clients *inputClientId = (audio_input_clients*) data.readIntPtr();
+            reply->writeInt32(closeInput((audio_io_handle_t) data.readInt32(), inputClientId));
+#else
             reply->writeInt32(closeInput((audio_io_handle_t) data.readInt32()));
+#endif
             return NO_ERROR;
         } break;
         case SET_STREAM_OUTPUT: {
@@ -1128,6 +1211,18 @@ status_t BnAudioFlinger::onTransact(
             reply->writeInt32(setLowRamDevice(isLowRamDevice));
             return NO_ERROR;
         } break;
+#ifdef STE_AUDIO
+        case READ_INPUT: {
+            CHECK_INTERFACE(IAudioFlinger, data, reply);
+            audio_io_handle_t input = data.readInt32();
+            audio_input_clients inputClientId = (audio_input_clients) data.readInt32();
+            void* buffer = (void*) data.readIntPtr();
+            uint32_t bytes = data.readInt32();
+            uint32_t *pOverwrittenBytes = (uint32_t*) data.readIntPtr();
+            reply->writeInt32(readInput(input, inputClientId, buffer, bytes, pOverwrittenBytes));
+            return NO_ERROR;
+        } break;
+#endif
         default:
             return BBinder::onTransact(code, data, reply, flags);
     }
diff --git a/frameworks/av/media/libmedia/IAudioPolicyService.cpp b/frameworks/av/media/libmedia/IAudioPolicyService.cpp
index 4be3c09..5397875 100644
--- a/frameworks/av/media/libmedia/IAudioPolicyService.cpp
+++ b/frameworks/av/media/libmedia/IAudioPolicyService.cpp
@@ -186,7 +186,12 @@ public:
                                     uint32_t samplingRate,
                                     audio_format_t format,
                                     audio_channel_mask_t channelMask,
+#ifdef STE_AUDIO
+                                    int audioSession,
+                                    audio_input_clients *inputClientId)
+#else
                                     int audioSession)
+#endif
     {
         Parcel data, reply;
         data.writeInterfaceToken(IAudioPolicyService::getInterfaceDescriptor());
@@ -194,6 +199,9 @@ public:
         data.writeInt32(samplingRate);
         data.writeInt32(static_cast <uint32_t>(format));
         data.writeInt32(channelMask);
+#ifdef STE_AUDIO
+        data.writeIntPtr((intptr_t)inputClientId);
+#endif
         data.writeInt32(audioSession);
         remote()->transact(GET_INPUT, data, &reply);
         return static_cast <audio_io_handle_t> (reply.readInt32());
@@ -508,12 +516,21 @@ status_t BnAudioPolicyService::onTransact(
             uint32_t samplingRate = data.readInt32();
             audio_format_t format = (audio_format_t) data.readInt32();
             audio_channel_mask_t channelMask = data.readInt32();
+#ifdef STE_AUDIO
+            audio_input_clients *inputClientId =
+                    (audio_input_clients*) data.readIntPtr();
+#endif
             int audioSession = data.readInt32();
             audio_io_handle_t input = getInput(inputSource,
                                                samplingRate,
                                                format,
                                                channelMask,
+#ifdef STE_AUDIO
+                                               audioSession,
+                                               inputClientId);
+#else
                                                audioSession);
+#endif
             reply->writeInt32(static_cast <int>(input));
             return NO_ERROR;
         } break;
diff --git a/frameworks/av/media/libnbaio/AudioStreamOutSink.cpp b/frameworks/av/media/libnbaio/AudioStreamOutSink.cpp
index e4341d7..1290b3f 100644
--- a/frameworks/av/media/libnbaio/AudioStreamOutSink.cpp
+++ b/frameworks/av/media/libnbaio/AudioStreamOutSink.cpp
@@ -81,6 +81,9 @@ status_t AudioStreamOutSink::getNextWriteTimestamp(int64_t *timestamp) {
 
 status_t AudioStreamOutSink::getTimestamp(AudioTimestamp& timestamp)
 {
+#ifdef STE_HARDWARE
+        return INVALID_OPERATION;
+#endif
     if (mStream->get_presentation_position == NULL) {
         return INVALID_OPERATION;
     }
diff --git a/frameworks/av/media/libstagefright/ACodec.cpp b/frameworks/av/media/libstagefright/ACodec.cpp
index 76a3358..a7be7dd 100644
--- a/frameworks/av/media/libstagefright/ACodec.cpp
+++ b/frameworks/av/media/libstagefright/ACodec.cpp
@@ -564,7 +564,11 @@ status_t ACodec::configureOutputBuffersFromNativeWindow(
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
-            def.format.video.eColorFormat);
+#ifdef STE_HARDWARE
+            OMXCodec::OmxToHALFormat(def.format.video.eColorFormat));
+#else
+             def.format.video.eColorFormat);
+#endif
 
     if (err != 0) {
         ALOGE("native_window_set_buffers_geometry failed: %s (%d)",
@@ -1679,6 +1683,20 @@ status_t ACodec::setSupportedOutputFormat() {
     CHECK_EQ(err, (status_t)OK);
     CHECK_EQ((int)format.eCompressionFormat, (int)OMX_VIDEO_CodingUnused);
 
+    CHECK(format.eColorFormat == OMX_COLOR_FormatYUV420Planar
+           || format.eColorFormat == OMX_COLOR_FormatYUV420SemiPlanar
+           || format.eColorFormat == OMX_COLOR_FormatCbYCrY
+           || format.eColorFormat == OMX_TI_COLOR_FormatYUV420PackedSemiPlanar
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYVU420SemiPlanar
+#ifdef QCOM_HARDWARE
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYVU420PackedSemiPlanar32m4ka
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYUV420PackedSemiPlanar64x32Tile2m8ka
+#endif
+#ifdef STE_HARDWARE
+           || format.eColorFormat == OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB
+#endif
+         );
+
     return mOMX->setParameter(
             mNode, OMX_IndexParamVideoPortFormat,
             &format, sizeof(format));
diff --git a/frameworks/av/media/libstagefright/CameraSource.cpp b/frameworks/av/media/libstagefright/CameraSource.cpp
index 3017fe7..60cf1fd 100644
--- a/frameworks/av/media/libstagefright/CameraSource.cpp
+++ b/frameworks/av/media/libstagefright/CameraSource.cpp
@@ -110,10 +110,16 @@ static int32_t getColorFormat(const char* colorFormat) {
     if (!strcmp(colorFormat, "OMX_TI_COLOR_FormatYUV420PackedSemiPlanar")) {
        return OMX_TI_COLOR_FormatYUV420PackedSemiPlanar;
     }
-
+/*
     if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_ANDROID_OPAQUE)) {
         return OMX_COLOR_FormatAndroidOpaque;
     }
+*/
+#ifdef STE_HARDWARE
+    if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_YUV420MB)) {
+       return OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB;
+    }
+#endif
 
     ALOGE("Uknown color format (%s), please add it to "
          "CameraSource::getColorFormat", colorFormat);
@@ -555,13 +561,22 @@ status_t CameraSource::initWithCameraAccess(
 
     // XXX: query camera for the stride and slice height
     // when the capability becomes available.
+#ifdef STE_HARDWARE
+    int stride = newCameraParams.getInt(CameraParameters::KEY_RECORD_STRIDE);
+    int sliceHeight = newCameraParams.getInt(CameraParameters::KEY_RECORD_SLICE_HEIGHT);
+#endif
     mMeta = new MetaData;
     mMeta->setCString(kKeyMIMEType,  MEDIA_MIMETYPE_VIDEO_RAW);
     mMeta->setInt32(kKeyColorFormat, mColorFormat);
     mMeta->setInt32(kKeyWidth,       mVideoSize.width);
     mMeta->setInt32(kKeyHeight,      mVideoSize.height);
+#ifdef STE_HARDWARE
+    mMeta->setInt32(kKeyStride,      stride != -1 ? stride : mVideoSize.width);
+    mMeta->setInt32(kKeySliceHeight, sliceHeight != -1 ? sliceHeight : mVideoSize.height);
+#else
     mMeta->setInt32(kKeyStride,      mVideoSize.width);
     mMeta->setInt32(kKeySliceHeight, mVideoSize.height);
+#endif
     mMeta->setInt32(kKeyFrameRate,   mVideoFrameRate);
     return OK;
 }
diff --git a/frameworks/av/media/libstagefright/MediaDefs.cpp b/frameworks/av/media/libstagefright/MediaDefs.cpp
index b5d4e44..2eb5c9e 100644
--- a/frameworks/av/media/libstagefright/MediaDefs.cpp
+++ b/frameworks/av/media/libstagefright/MediaDefs.cpp
@@ -25,8 +25,14 @@ const char *MEDIA_MIMETYPE_VIDEO_VP9 = "video/x-vnd.on2.vp9";
 const char *MEDIA_MIMETYPE_VIDEO_AVC = "video/avc";
 const char *MEDIA_MIMETYPE_VIDEO_MPEG4 = "video/mp4v-es";
 const char *MEDIA_MIMETYPE_VIDEO_H263 = "video/3gpp";
+#ifdef STE_HARDWARE
+const char *MEDIA_MIMETYPE_VIDEO_H263_SW = "video/3gpp-sw";
+#endif
 const char *MEDIA_MIMETYPE_VIDEO_MPEG2 = "video/mpeg2";
 const char *MEDIA_MIMETYPE_VIDEO_RAW = "video/raw";
+#ifdef STE_HARDWARE
+const char *MEDIA_MIMETYPE_VIDEO_VC1 = "video/vc1";
+#endif
 
 const char *MEDIA_MIMETYPE_AUDIO_AMR_NB = "audio/3gpp";
 const char *MEDIA_MIMETYPE_AUDIO_AMR_WB = "audio/amr-wb";
diff --git a/frameworks/av/media/libstagefright/OMXCodec.cpp b/frameworks/av/media/libstagefright/OMXCodec.cpp
index 43736ad..53ceff5 100644
--- a/frameworks/av/media/libstagefright/OMXCodec.cpp
+++ b/frameworks/av/media/libstagefright/OMXCodec.cpp
@@ -232,6 +232,20 @@ void OMXCodec::findMatchingCodecs(
     }
 }
 
+#ifdef STE_HARDWARE
+uint32_t OMXCodec::OmxToHALFormat(OMX_COLOR_FORMATTYPE omxValue) {
+    switch (omxValue) {
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+            return HAL_PIXEL_FORMAT_YCBCR42XMBN;
+        case OMX_COLOR_FormatYUV420Planar:
+            return HAL_PIXEL_FORMAT_YCbCr_420_P;
+        default:
+            ALOGI("Unknown OMX pixel format (0x%X), passing it on unchanged", omxValue);
+            return omxValue;
+    }
+}
+#endif
+
 // static
 uint32_t OMXCodec::getComponentQuirks(
         const MediaCodecList *list, size_t index) {
@@ -248,7 +262,12 @@ uint32_t OMXCodec::getComponentQuirks(
                 index, "output-buffers-are-unreadable")) {
         quirks |= kOutputBuffersAreUnreadable;
     }
-
+#ifdef STE_HARDWARE
+    if (list->codecHasQuirk(
+                index, "requires-store-metadata-before-idle")) {
+      quirks |= kRequiresStoreMetaDataBeforeIdle;
+    }
+#endif
     return quirks;
 }

@@ -707,6 +727,9 @@ static size_t getFrameSize(
         case OMX_COLOR_FormatYUV420Planar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
+#ifdef STE_HARDWARE
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+#endif
         /*
         * FIXME: For the Opaque color format, the frame size does not
         * need to be (w*h*3)/2. It just needs to
@@ -1384,6 +1407,10 @@ void OMXCodec::setComponentRole(
             "video_decoder.mpeg4", "video_encoder.mpeg4" },
         { MEDIA_MIMETYPE_VIDEO_H263,
             "video_decoder.h263", "video_encoder.h263" },
+#ifdef STE_HARDWARE
+        { MEDIA_MIMETYPE_VIDEO_VC1,
+            "video_decoder.vc1", "video_encoder.vc1" },
+#endif
         { MEDIA_MIMETYPE_VIDEO_VP8,
             "video_decoder.vp8", "video_encoder.vp8" },
         { MEDIA_MIMETYPE_VIDEO_VP9,
@@ -1463,6 +1490,16 @@ status_t OMXCodec::init() {
     CHECK_EQ((int)mState, (int)LOADED);
 
     status_t err;
+#ifdef STE_HARDWARE
+    if ((mQuirks & kRequiresStoreMetaDataBeforeIdle)
+        && (mFlags & kStoreMetaDataInVideoBuffers)) {
+        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
+        if (err != OK) {
+            ALOGE("Storing meta data in video buffers is not supported");
+            return err;
+        }
+    }
+#endif
     if (!(mQuirks & kRequiresLoadedToIdleAfterAllocation)) {
         err = mOMX->sendCommand(mNode, OMX_CommandStateSet, OMX_StateIdle);
         CHECK_EQ(err, (status_t)OK);
@@ -1518,7 +1555,12 @@ status_t OMXCodec::allocateBuffersOnPort(OMX_U32 portIndex) {
     }
 
     status_t err = OK;
+#ifdef STE_HARDWARE
+    if (!(mQuirks & kRequiresStoreMetaDataBeforeIdle)
+            && (mFlags & kStoreMetaDataInVideoBuffers)
+#else
     if ((mFlags & kStoreMetaDataInVideoBuffers)
+#endif
             && portIndex == kPortIndexInput) {
         err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
         if (err != OK) {
@@ -1717,7 +1759,11 @@ status_t OMXCodec::allocateOutputBuffersFromNativeWindow() {
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
+#ifdef STE_HARDWARE
+            OmxToHALFormat(def.format.video.eColorFormat));
+#else
             def.format.video.eColorFormat);
+#endif
 
     if (err != 0) {
         ALOGE("native_window_set_buffers_geometry failed: %s (%d)",
@@ -4045,6 +4091,9 @@ static const char *videoCompressionFormatString(OMX_VIDEO_CODINGTYPE type) {
         "OMX_VIDEO_CodingRV",
         "OMX_VIDEO_CodingAVC",
         "OMX_VIDEO_CodingMJPEG",
+#ifdef STE_HARDWARE
+        "OMX_VIDEO_CodingVC1",
+#endif
     };
 
     size_t numNames = sizeof(kNames) / sizeof(kNames[0]);
diff --git a/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp b/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
index 6b934d4..75971f2 100644
--- a/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
+++ b/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
@@ -57,7 +57,11 @@ SurfaceMediaSource::SurfaceMediaSource(uint32_t bufferWidth, uint32_t bufferHeig
     mBufferQueue = new BufferQueue();
     mBufferQueue->setDefaultBufferSize(bufferWidth, bufferHeight);
     mBufferQueue->setConsumerUsageBits(GRALLOC_USAGE_HW_VIDEO_ENCODER |
+#ifdef STE_HARDWARE
+            GRALLOC_USAGE_HW_2D);
+#else
             GRALLOC_USAGE_HW_TEXTURE);
+#endif
 
     sp<ISurfaceComposer> composer(ComposerService::getComposerService());
 
diff --git a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
index 597167f..1c8e789 100644
--- a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
+++ b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
@@ -47,6 +47,9 @@ bool ColorConverter::isValid() const {
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
+#ifdef STE_HARDWARE
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+#endif
             return true;
 
         default:
@@ -122,6 +125,12 @@ status_t ColorConverter::convert(
             err = convertTIYUV420PackedSemiPlanar(src, dst);
             break;
 
+#ifdef STE_HARDWARE
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+            err = convertSTEYUV420PackedSemiPlanarMB(src, dst);
+            break;
+#endif
+
         default:
         {
             CHECK(!"Should not be here. Unknown color conversion.");
@@ -506,6 +515,145 @@ status_t ColorConverter::convertTIYUV420PackedSemiPlanar(
     return OK;
 }
 
+#ifdef STE_HARDWARE
+status_t ColorConverter::convertSTEYUV420PackedSemiPlanarMB(
+        const BitmapParams &src, const BitmapParams &dst) {
+
+    if (!((dst.mWidth & 1) == 0
+            && src.mCropLeft == 0
+            && src.mCropTop == 0
+            && src.cropWidth() == dst.cropWidth()
+            && src.cropHeight() == dst.cropHeight())) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    OMX_U32 mx = src.mWidth / 16;
+    OMX_U32 my = src.mHeight / 16;
+    OMX_U32 lx, ly;
+    OMX_U32 *pChroma, *pLuma = (OMX_U32 *)src.mBits;
+
+    pChroma = (OMX_U32 *)src.mBits + mx * my * 64;
+    for (ly = 0; ly < my; ly++) {
+        for (lx = 0; lx < mx; lx++) {
+            OMX_U32 col, row, lumaWord, chromaWord1 = 0, rgbWord, i;
+            OMX_U8 y[4], cb[4], cr[4], r[4], g[4], b[4];
+            OMX_U32 *dstBuf, *locBuf;
+            OMX_U32 *pBurstLuma = 0, *pBurstChroma = 0;
+            OMX_U32 *pWordLuma = 0, *pWordChroma = 0;
+            OMX_U8 nbOfBlock;
+
+            dstBuf = ((OMX_U32 *)dst.mBits) + (ly * 16) * dst.mWidth / 2;
+            dstBuf += (lx * 16) / 2;
+
+            pBurstLuma = pLuma;
+            pBurstChroma = pChroma;
+
+            for (col = 0; col < 2; col++) {
+                // conversion of a macroblock
+                for (nbOfBlock = 0; nbOfBlock < 2; nbOfBlock++) {
+                    locBuf = dstBuf + 4 * col + 2 * nbOfBlock;
+                    OMX_U32 dstRowOrigo = ly * 16 * dst.mWidth;
+
+                    switch (nbOfBlock) {
+                    case 0:
+                        pWordLuma = pBurstLuma;
+                        pWordChroma = pBurstChroma;
+                        break;
+                    case 1:
+                        pWordLuma = pBurstLuma + 1;
+                        pWordChroma = pBurstChroma + 1;
+                        break;
+                    }
+                    for (row = 0; row < 16; row++) {
+
+                        // Check for cropping on the y axis
+                        if (ly * 16 + row >= dst.mHeight) {
+                            break;
+                        }
+
+                        lumaWord = *pWordLuma;
+                        pWordLuma += 2;
+                        if (row % 2 == 0) {
+                            chromaWord1 = *pWordChroma;
+                            pWordChroma += 2;
+                        }
+
+                        y[3] = ((lumaWord >> 24) & 0xff);
+                        y[2] = ((lumaWord >> 16) & 0xff);
+                        y[1] = ((lumaWord >>  8) & 0xff);
+                        y[0] = ((lumaWord >>  0) & 0xff);
+
+                        cb[0] = cb[1] = ((chromaWord1 >>  0) & 0xff);
+                        cb[2] = cb[3] = ((chromaWord1 >> 16) & 0xff);
+                        cr[0] = cr[1] = ((chromaWord1 >>  8) & 0xff);
+                        cr[2] = cr[3] = ((chromaWord1 >> 24) & 0xff);
+
+                        for (i = 0; i < 4; i++) {
+
+                            int32_t rW,gW,bW;
+
+                            rW = 298 * y[i] + 408 * cr[i] - 57059;
+                            gW = 298 * y[i] - 100 * cb[i] - 208 * cr[i] + 34713;
+                            bW = 298 * y[i] + 516 * cb[i] - 70887;
+
+                            if (rW < 0) {
+                                r[i] = 0;
+                            } else if (rW >= 65536) {
+                                r[i] = 255;
+                            } else {
+                                r[i] = (rW >> 8);
+                            }
+                            if (gW < 0) {
+                                g[i] = 0;
+                            } else if (gW >= 65536) {
+                                g[i] = 255;
+                            } else {
+                                g[i] = (gW >> 8);
+                            }
+                            if (bW < 0) {
+                                b[i] = 0;
+                            } else if (bW >= 65536) {
+                                b[i] = 255;
+                            } else {
+                                b[i] = (bW >> 8);
+                            }
+                            r[i] >>= 3;
+                            g[i] >>= 2;
+                            b[i] >>= 3;
+                        }
+                        for (i = 0; i < 4; i += 2) {
+
+                            // Check for cropping on the x axis
+                            OMX_U32 rowPos = (locBuf - (OMX_U32 *)dst.mBits) * 2 - dstRowOrigo;
+                            if (rowPos >= dst.mWidth) {
+                                locBuf++;
+                                continue;
+                            }
+
+                            rgbWord = (r[i + 1] << 27) +
+                                (g[i + 1] << 21) +
+                                (b[i + 1] << 16) +
+                                (r[i] << 11) +
+                                (g[i] << 5) +
+                                (b[i] << 0);
+                            *locBuf++ = rgbWord;
+                        }
+                        locBuf += dst.mWidth / 2 - 2;
+                        dstRowOrigo += dst.mWidth;
+                    } //end of for 16 loop
+                }  //end of 2 block loop
+                pBurstLuma += 32;
+                pBurstChroma += 16;
+            } // end of 2 col loop
+            pLuma   += 64;
+            pChroma += 32;
+        }
+    }
+
+    return OK;
+}
+#endif
+
 uint8_t *ColorConverter::initClip() {
     static const signed kClipMin = -278;
     static const signed kClipMax = 535;
diff --git a/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp b/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp
index d6cde73..0780ad2 100644
--- a/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp
+++ b/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp
@@ -34,6 +34,9 @@ static const struct {
     const char *mRole;
 
 } kComponents[] = {
+#ifdef STE_HARDWARE
+    { "OMX.ST.aac.decoder", "ste_aacdec", "audio_decoder.aac" },
+#endif
     { "OMX.google.aac.decoder", "aacdec", "audio_decoder.aac" },
     { "OMX.google.aac.encoder", "aacenc", "audio_encoder.aac" },
     { "OMX.google.amrnb.decoder", "amrdec", "audio_decoder.amrnb" },
@@ -48,6 +51,9 @@ static const struct {
     { "OMX.google.h263.encoder", "mpeg4enc", "video_encoder.h263" },
     { "OMX.google.mpeg4.decoder", "mpeg4dec", "video_decoder.mpeg4" },
     { "OMX.google.mpeg4.encoder", "mpeg4enc", "video_encoder.mpeg4" },
+#ifdef STE_HARDWARE
+    { "OMX.ST.mp3.decoder", "ste_mp3dec", "audio_decoder.mp3" },
+#endif
     { "OMX.google.mp3.decoder", "mp3dec", "audio_decoder.mp3" },
     { "OMX.google.vorbis.decoder", "vorbisdec", "audio_decoder.vorbis" },
     { "OMX.google.vp8.decoder", "vpxdec", "video_decoder.vp8" },
diff --git a/frameworks/av/services/audioflinger/Android.mk b/frameworks/av/services/audioflinger/Android.mk
index b895027..786fbbc 100644
--- a/frameworks/av/services/audioflinger/Android.mk
+++ b/frameworks/av/services/audioflinger/Android.mk
@@ -13,6 +13,10 @@ include $(BUILD_STATIC_LIBRARY)
 
 include $(CLEAR_VARS)
 
+ifeq ($(BOARD_USES_STE_HARDWARE),true)
+LOCAL_CFLAGS += -DSTE_AUDIO
+LOCAL_CFLAGS += -Wno-conversion -fpermissive
+endif
 LOCAL_SRC_FILES:=               \
     AudioFlinger.cpp            \
     Threads.cpp                 \
diff --git a/frameworks/av/services/audioflinger/AudioFlinger.cpp b/frameworks/av/services/audioflinger/AudioFlinger.cpp
index 26dac95..af1303c 100644
--- a/frameworks/av/services/audioflinger/AudioFlinger.cpp
+++ b/frameworks/av/services/audioflinger/AudioFlinger.cpp
@@ -1023,6 +1025,20 @@ uint32_t AudioFlinger::getInputFramesLost(audio_io_handle_t ioHandle) const
     return 0;
 }
 
+#ifdef STE_AUDIO
+size_t AudioFlinger::readInput(audio_io_handle_t input, audio_input_clients inputClientId,
+        void *buffer, uint32_t bytes, uint32_t *pOverwrittenBytes)
+{
+    if (input == 0 || buffer == NULL) {
+        return 0;
+    }
+
+    AudioStreamIn* InStream = (AudioStreamIn*)input;
+
+    return 0;
+}
+#endif
+
 status_t AudioFlinger::setVoiceVolume(float value)
 {
     status_t ret = initCheck();
@@ -1538,7 +1575,11 @@ audio_io_handle_t AudioFlinger::openOutput(audio_module_handle_t module,
         thread->audioConfigChanged_l(AudioSystem::OUTPUT_OPENED);
 
         // the first primary output opened designates the primary hw device
+#ifdef STE_AUDIO
+        if ( mPrimaryHardwareDev == NULL ) {
+#else
         if ((mPrimaryHardwareDev == NULL) && (flags & AUDIO_OUTPUT_FLAG_PRIMARY)) {
+#endif
             ALOGI("Using module %d has the primary audio interface", module);
             mPrimaryHardwareDev = outHwDev;
 
@@ -1668,11 +1709,50 @@ status_t AudioFlinger::restoreOutput(audio_io_handle_t output)
     return NO_ERROR;
 }
 
+#ifdef STE_AUDIO
+uint32_t *AudioFlinger::addInputClient(uint32_t clientId)
+{
+    Mutex::Autolock _l(mLock);
+
+    uint32_t *pNewClient = new uint32_t;
+    if (pNewClient) {
+        *pNewClient = clientId;
+        mInputClients.add(pNewClient);
+    }
+
+    return pNewClient;
+}
+
+status_t AudioFlinger::removeInputClient(uint32_t *pClientId)
+{
+    status_t result = NO_ERROR;
+
+    Mutex::Autolock _l(mLock);
+
+    if (pClientId == NULL) {
+        result = BAD_VALUE;
+    } else if (mInputClients.remove(pClientId) < 0) {
+        result = BAD_VALUE;
+    } else {
+        // the pointer was found in the vector and is non-NULL, so it must point to memory	8071
+        // allocated by addInputClient => free it.
+        delete pClientId;
+    }
+
+    return result;
+}
+#endif
+
 audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
                                           audio_devices_t *pDevices,
                                           uint32_t *pSamplingRate,
                                           audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                          audio_channel_mask_t *pChannelMask,
+                                          audio_input_clients *pInputClientId)
+#else
                                           audio_channel_mask_t *pChannelMask)
+#endif
 {
     status_t status;
     RecordThread *thread = NULL;
@@ -1686,6 +1766,10 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
     audio_channel_mask_t reqChannels = config.channel_mask;
     audio_stream_in_t *inStream = NULL;
     AudioHwDevice *inHwDev;
+#ifdef STE_AUDIO
+    bool returnRecordThread = true;
+    audio_input_clients inputClientId;
+#endif
 
     if (pDevices == NULL || *pDevices == 0) {
         return 0;
@@ -1734,6 +1734,11 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
     inHwDev = findSuitableHwDev_l(module, *pDevices);
     if (inHwDev == NULL)
         return 0;
+#ifdef STE_AUDIO
+    if (pInputClientId != NULL && *pInputClientId == AUDIO_INPUT_CLIENT_PLAYBACK) {
+        returnRecordThread = false;
+    }
+#endif

     audio_hw_device_t *inHwHal = inHwDev->hwDevice();
     audio_io_handle_t id = nextUniqueId();
@@ -1749,17 +1754,33 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
                                         &inStream);
 #endif
     ALOGV("openInput() openInputStream returned input %p, SamplingRate %d, Format %d, Channels %x, "
+#ifdef STE_AUDIO
+            "status %d, pInputClientId %p",
+#else
             "status %d",
+#endif
             inStream,
             config.sample_rate,
             config.format,
             config.channel_mask,
+#ifdef STE_AUDIO
+            status,
+            pInputClientId);
+#else
             status);
+#endif
 
     // If the input could not be opened with the requested parameters and we can handle the
     // conversion internally, try to open again with the proposed parameters. The AudioFlinger can
     // resample the input and do mono to stereo or stereo to mono conversions on 16 bit PCM inputs.
-    if (status == BAD_VALUE &&
+#ifdef STE_AUDIO
+    if (inStream == NULL && status == ALREADY_EXISTS) {
+        ALOGD("Input already exists");
+        return 0;
+    } else if (inStream == NULL && status == BAD_VALUE &&
+#else
+     if (status == BAD_VALUE &&
+#endif
         reqFormat == config.format && config.format == AUDIO_FORMAT_PCM_16_BIT &&
         (config.sample_rate <= 2 * reqSamplingRate) &&
         (popcount(config.channel_mask) <= FCC_2) && (popcount(reqChannels) <= FCC_2)) {
@@ -1784,7 +1890,12 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
                                   reqChannels,
                                   id,
                                   primaryOutputDevice_l(),
+#ifdef STE_AUDIO
+                                  *pDevices,
+                                  inputClientId
+#else
                                   *pDevices
+#endif
 #ifdef TEE_SINK
                                   , teeSink
 #endif
@@ -1801,6 +1912,12 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
             *pChannelMask = reqChannels;
         }
 
+#ifdef STE_AUDIO
+        if (pInputClientId != NULL) {
+            *pInputClientId = inputClientId;
+        }
+#endif
+
         // notify client processes of the new input creation
         thread->audioConfigChanged_l(AudioSystem::INPUT_OPENED);
         return id;
@@ -1809,10 +1926,45 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
     return 0;
 }
 
+#ifdef STE_AUDIO
+status_t AudioFlinger::closeInput(audio_io_handle_t input, audio_input_clients *inputClientId)
+{
+    // keep strong reference on the record thread so that
+    // it is not destroyed while exit() is executed
+    Mutex::Autolock _l(mLock);
+    AudioStreamIn* stream = (AudioStreamIn*)input;
+    audio_input_clients clientId = (audio_input_clients) *inputClientId;
+    sp <RecordThread> thread;
+    thread = checkRecordThread_l(input);
+    if (thread != NULL) {
+        stream = thread->getInput();
+    }
+    if (inputClientId == NULL) {
+        if (thread == NULL) {
+            return BAD_VALUE;
+        }
+        ALOGV("closeInput() %d", input);
+        void *param2 = 0;
+        audioConfigChanged_l(AudioSystem::INPUT_CLOSED, input, param2);
+        mRecordThreads.removeItem(input);
+    }
+
+    AudioStreamIn *in = (AudioStreamIn *)stream;
+    in->hwDev()->close_input_stream(in->hwDev(), in->stream);
+    delete in;
+
+    if (thread != NULL) {
+        thread->exit();
+    }
+
+    return NO_ERROR;
+}
+#else
 status_t AudioFlinger::closeInput(audio_io_handle_t input)
 {
     return closeInput_nonvirtual(input);
 }
+#endif
 
 status_t AudioFlinger::closeInput_nonvirtual(audio_io_handle_t input)
 {
diff --git a/frameworks/av/services/audioflinger/AudioFlinger.h b/frameworks/av/services/audioflinger/AudioFlinger.h
index 7320144..742eac4 100644
--- a/frameworks/av/services/audioflinger/AudioFlinger.h
+++ b/frameworks/av/services/audioflinger/AudioFlinger.h
@@ -174,13 +184,32 @@ public:
 
     virtual status_t restoreOutput(audio_io_handle_t output);
 
+#ifdef STE_AUDIO
+    virtual uint32_t *addInputClient(uint32_t clientId);
+
+    virtual status_t removeInputClient(uint32_t *pClientId);
+#endif
+
     virtual audio_io_handle_t openInput(audio_module_handle_t module,
                                         audio_devices_t *pDevices,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                        audio_channel_mask_t *pChannelMask,
+			                                        audio_input_clients *pInputClientId = NULL);
+
+    virtual status_t closeInput(audio_io_handle_t input, audio_input_clients *inputClientId = NULL);
+    virtual size_t readInput(audio_io_handle_t input,
+                            audio_input_clients inputClientId,
+                            void *buffer,
+                            uint32_t bytes,
+                            uint32_t *pOverwrittenBytes);
+
+#else
                                         audio_channel_mask_t *pChannelMask);
 
     virtual status_t closeInput(audio_io_handle_t input);
+#endif
 
     virtual status_t setStreamOutput(audio_stream_type_t stream, audio_io_handle_t output);
 
@@ -594,6 +623,9 @@ private:
                 // protected by mLock
                 Vector<AudioSessionRef*> mAudioSessionRefs;
 
+#ifdef STE_AUDIO
+                SortedVector<uint32_t*> mInputClients;
+#endif
                 float       masterVolume_l() const;
                 bool        masterMute_l() const;
                 audio_module_handle_t loadHwModule_l(const char *name);
diff --git a/frameworks/av/services/audioflinger/AudioPolicyService.cpp b/frameworks/av/services/audioflinger/AudioPolicyService.cpp
index a37272d..177911d 100644
--- a/frameworks/av/services/audioflinger/AudioPolicyService.cpp
+++ b/frameworks/av/services/audioflinger/AudioPolicyService.cpp
@@ -290,7 +290,12 @@ audio_io_handle_t AudioPolicyService::getInput(audio_source_t inputSource,
                                     uint32_t samplingRate,
                                     audio_format_t format,
                                     audio_channel_mask_t channelMask,
+#ifdef STE_AUDIO
+                                    int audioSession,
+                                    audio_input_clients *inputClientId)
+#else
                                     int audioSession)
+#endif
 {
     if (mpAudioPolicy == NULL) {
         return 0;
@@ -307,7 +312,11 @@ audio_io_handle_t AudioPolicyService::getInput(audio_source_t inputSource,
     Mutex::Autolock _l(mLock);
     // the audio_in_acoustics_t parameter is ignored by get_input()
     audio_io_handle_t input = mpAudioPolicy->get_input(mpAudioPolicy, inputSource, samplingRate,
+#ifdef STE_AUDIO
+                                                   format, channelMask, (audio_in_acoustics_t) 0, inputClientId);
+#else
                                                    format, channelMask, (audio_in_acoustics_t) 0);
+#endif
 
     if (input == 0) {
         return input;
@@ -515,11 +524,14 @@ bool AudioPolicyService::isStreamActive(audio_stream_type_t stream, uint32_t inP
 
 bool AudioPolicyService::isStreamActiveRemotely(audio_stream_type_t stream, uint32_t inPastMs) const
 {
+#if !defined(MR1_AUDIO_BLOB)
     if (mpAudioPolicy == NULL) {
         return 0;
     }
     Mutex::Autolock _l(mLock);
     return mpAudioPolicy->is_stream_active_remotely(mpAudioPolicy, stream, inPastMs);
+#endif
+    return 0;
 }
 
 bool AudioPolicyService::isSourceActive(audio_source_t source) const
@@ -1052,6 +1064,14 @@ void AudioPolicyService::AudioCommandThread::insertCommand_l(AudioCommand *comma
         for (size_t k = i + 1; k < mAudioCommands.size(); k++) {
             if (mAudioCommands[k] == removedCommands[j]) {
                 ALOGV("suppressing command: %d", mAudioCommands[k]->mCommand);
+#ifdef STE_AUDIO
+                // for commands that are not filtered,
+                // command->mParam is deleted in threadLoop
+                ALOGV("deleting mParam %p for command: %d",
+                        mAudioCommands[k]->mParam, mAudioCommands[k]->mCommand);
+                delete mAudioCommands[k]->mParam;
+                mAudioCommands[k]->mParam = NULL;
+#endif
                 mAudioCommands.removeAt(k);
                 break;
             }
@@ -1134,7 +1154,12 @@ int AudioPolicyService::setVoiceVolume(float volume, int delayMs)
 {
     return (int)mAudioCommandThread->voiceVolumeCommand(volume, delayMs);
 }
-
+#ifdef STE_HARDWARE
+bool AudioPolicyService::isOffloadSupported(const audio_offload_info_t& info)
+{
+    return false;
+}
+#else
 bool AudioPolicyService::isOffloadSupported(const audio_offload_info_t& info)
 {
     if (mpAudioPolicy == NULL) {
@@ -1149,6 +1174,7 @@ bool AudioPolicyService::isOffloadSupported(const audio_offload_info_t& info)
 
     return mpAudioPolicy->is_offload_supported(mpAudioPolicy, &info);
 }
+#endif
 
 // ----------------------------------------------------------------------------
 // Audio pre-processing configuration
@@ -1551,7 +1577,12 @@ static audio_io_handle_t aps_open_input(void *service,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
                                         audio_channel_mask_t *pChannelMask,
+#ifdef STE_AUDIO
+                                        audio_in_acoustics_t acoustics,
+			                    audio_input_clients *inputClientId)
+#else
                                         audio_in_acoustics_t acoustics)
+#endif
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
@@ -1559,7 +1590,11 @@ static audio_io_handle_t aps_open_input(void *service,
         return 0;
     }
 
+#ifdef STE_AUDIO
+    return af->openInput((audio_module_handle_t)0, pDevices, pSamplingRate, pFormat, pChannelMask, inputClientId);
+#else
     return af->openInput((audio_module_handle_t)0, pDevices, pSamplingRate, pFormat, pChannelMask);
+#endif
 }
 
 static audio_io_handle_t aps_open_input_on_module(void *service,
@@ -1567,7 +1602,12 @@ static audio_io_handle_t aps_open_input_on_module(void *service,
                                                   audio_devices_t *pDevices,
                                                   uint32_t *pSamplingRate,
                                                   audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                                  audio_channel_mask_t *pChannelMask,
+                                                  audio_input_clients *inputClientId)
+#else
                                                   audio_channel_mask_t *pChannelMask)
+#endif
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
@@ -1575,16 +1615,29 @@ static audio_io_handle_t aps_open_input_on_module(void *service,
         return 0;
     }
 
+#ifdef STE_AUDIO
+    return af->openInput(module, pDevices, pSamplingRate, pFormat, pChannelMask, inputClientId);
+#else
     return af->openInput(module, pDevices, pSamplingRate, pFormat, pChannelMask);
+#endif
 }
 
+#ifdef STE_AUDIO
+static int aps_close_input(void *service, audio_io_handle_t input,
+                            audio_input_clients *inputClientId = NULL)
+#else
 static int aps_close_input(void *service, audio_io_handle_t input)
+#endif
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0)
         return PERMISSION_DENIED;
 
+#ifdef STE_AUDIO
+    return af->closeInput(input, inputClientId);
+#else
     return af->closeInput(input);
+#endif
 }
 
 static int aps_set_stream_output(void *service, audio_stream_type_t stream,
diff --git a/frameworks/av/services/audioflinger/AudioPolicyService.h b/frameworks/av/services/audioflinger/AudioPolicyService.h
index ae053a9..cb64b1c 100644
--- a/frameworks/av/services/audioflinger/AudioPolicyService.h
+++ b/frameworks/av/services/audioflinger/AudioPolicyService.h
@@ -80,7 +80,12 @@ public:
                                     uint32_t samplingRate = 0,
                                     audio_format_t format = AUDIO_FORMAT_DEFAULT,
                                     audio_channel_mask_t channelMask = 0,
+#ifdef STE_AUDIO
+                                    int audioSession = 0,
+                                    audio_input_clients *inputClientId = NULL);
+#else
                                     int audioSession = 0);
+#endif
     virtual status_t startInput(audio_io_handle_t input);
     virtual status_t stopInput(audio_io_handle_t input);
     virtual void releaseInput(audio_io_handle_t input);
diff --git a/frameworks/av/services/audioflinger/Effects.h b/frameworks/av/services/audioflinger/Effects.h
index b717857..a909b89 100644
--- a/frameworks/av/services/audioflinger/Effects.h
+++ b/frameworks/av/services/audioflinger/Effects.h
@@ -215,6 +215,10 @@ protected:
     EffectHandle(const EffectHandle&);
     EffectHandle& operator =(const EffectHandle&);
 
+#ifdef STE_AUDIO
+    Mutex               mLock;          // mutex protecting mEffect pointer
+#endif
+
     sp<EffectModule> mEffect;           // pointer to controlled EffectModule
     sp<IEffectClient> mEffectClient;    // callback interface for client notifications
     /*const*/ sp<Client> mClient;       // client for shared memory allocation, see disconnect()
diff --git a/frameworks/av/services/audioflinger/PlaybackTracks.h b/frameworks/av/services/audioflinger/PlaybackTracks.h
index 43b77f3..c7c7342 100644
--- a/frameworks/av/services/audioflinger/PlaybackTracks.h
+++ b/frameworks/av/services/audioflinger/PlaybackTracks.h
@@ -52,7 +52,11 @@ public:
             audio_stream_type_t streamType() const {
                 return mStreamType;
             }
+#ifdef STE_HARDWARE
+            bool        isOffloaded() const { return 0; }
+#else
             bool        isOffloaded() const { return (mFlags & IAudioFlinger::TRACK_OFFLOAD) != 0; }
+#endif
             status_t    setParameters(const String8& keyValuePairs);
             status_t    attachAuxEffect(int EffectId);
             void        setAuxBuffer(int EffectId, int32_t *buffer);
diff --git a/frameworks/av/services/audioflinger/Threads.cpp b/frameworks/av/services/audioflinger/Threads.cpp
index 1da5147..ef51964 100644
--- a/frameworks/av/services/audioflinger/Threads.cpp
+++ b/frameworks/av/services/audioflinger/Threads.cpp
@@ -1558,6 +1558,9 @@ void AudioFlinger::PlaybackThread::audioConfigChanged_l(int event, int param) {
         break;
 
     case AudioSystem::STREAM_CONFIG_CHANGED:
+#ifdef STE_AUDIO
+    case AudioSystem::SINK_LATENCY_CHANGED:
+#endif
         param2 = &param;
     case AudioSystem::OUTPUT_CLOSED:
     default:
@@ -3411,6 +3414,12 @@ bool AudioFlinger::MixerThread::checkForNewParameters_l()
             }
         }
 
+#ifdef STE_AUDIO
+        if (param.getInt(String8(AudioParameter::keySinkLatency), value) == NO_ERROR) {
+            sendIoConfigEvent_l(AudioSystem::SINK_LATENCY_CHANGED, value);
+        }
+#endif
+
         if (status == NO_ERROR) {
             status = mOutput->stream->common.set_parameters(&mOutput->stream->common,
                                                     keyValuePair.string());
@@ -4372,7 +4381,12 @@ AudioFlinger::RecordThread::RecordThread(const sp<AudioFlinger>& audioFlinger,
                                          audio_channel_mask_t channelMask,
                                          audio_io_handle_t id,
                                          audio_devices_t outDevice,
+#ifdef STE_AUDIO
+                                         audio_devices_t inDevice,
+                                         audio_input_clients pInputClientId
+#else
                                          audio_devices_t inDevice
+#endif
 #ifdef TEE_SINK
                                          , const sp<NBAIO_Sink>& teeSink
 #endif
@@ -4389,7 +4403,9 @@ AudioFlinger::RecordThread::RecordThread(const sp<AudioFlinger>& audioFlinger,
 #endif
 {
     snprintf(mName, kNameLength, "AudioIn_%X", id);
-
+#ifdef STE_AUDIO
+    mInputClientId = pInputClientId;
+#endif
     readInputParameters();
 }
 
@@ -5288,6 +5304,14 @@ KeyedVector<int, bool> AudioFlinger::RecordThread::sessionIds() const
     return ids;
 }
 
+#ifdef STE_AUDIO
+AudioFlinger::AudioStreamIn* AudioFlinger::RecordThread::getInput() const
+{
+    Mutex::Autolock _l(mLock);
+    return mInput;
+}
+#endif
+
 AudioFlinger::AudioStreamIn* AudioFlinger::RecordThread::clearInput()
 {
     Mutex::Autolock _l(mLock);
diff --git a/frameworks/av/services/audioflinger/Threads.h b/frameworks/av/services/audioflinger/Threads.h
index a2fb874..6148aa7 100644
--- a/frameworks/av/services/audioflinger/Threads.h
+++ b/frameworks/av/services/audioflinger/Threads.h
@@ -851,7 +851,12 @@ public:
                     audio_channel_mask_t channelMask,
                     audio_io_handle_t id,
                     audio_devices_t outDevice,
+#ifdef STE_AUDIO
+                    audio_devices_t inDevice,
+                    audio_input_clients pinputClientId
+#else
                     audio_devices_t inDevice
+#endif
 #ifdef TEE_SINK
                     , const sp<NBAIO_Sink>& teeSink
 #endif
@@ -894,6 +899,7 @@ public:
             bool        stop(RecordTrack* recordTrack);
 
             void        dump(int fd, const Vector<String16>& args);
+            AudioStreamIn* getInput() const;
             AudioStreamIn* clearInput();
             virtual audio_stream_t* stream() const;
 
@@ -951,6 +957,9 @@ private:
             const uint32_t                      mReqChannelCount;
             const uint32_t                      mReqSampleRate;
             ssize_t                             mBytesRead;
+#ifdef STE_AUDIO
+            audio_input_clients                 mInputClientId;
+#endif
             // sync event triggering actual audio capture. Frames read before this event will
             // be dropped and therefore not read by the application.
             sp<SyncEvent>                       mSyncStartEvent;
diff --git a/frameworks/av/services/camera/libcameraservice/device1/CameraHardwareInterface.h b/frameworks/av/services/camera/libcameraservice/device1/CameraHardwareInterface.h
index 87b2807..362ccf9 100644
--- a/frameworks/av/services/camera/libcameraservice/device1/CameraHardwareInterface.h
+++ b/frameworks/av/services/camera/libcameraservice/device1/CameraHardwareInterface.h
@@ -636,6 +636,9 @@ private:
 
     static int __set_usage(struct preview_stream_ops* w, int usage)
     {
+#ifdef STE_HARDWARE
+        usage |= GRALLOC_USAGE_PRIVATE_0;
+#endif
         ANativeWindow *a = anw(w);
         return native_window_set_usage(a, usage);
     }
